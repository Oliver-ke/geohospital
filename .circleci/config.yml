version: '2.1'
orbs:
  aws-ecr: circleci/aws-ecr@7.0.0
  aws-eks: circleci/aws-eks@2.1.1
  kubernetes: circleci/kubernetes@1.3

commands:
  install-yd:
    description: "add yd to current job"
    steps:
      - run:
          name: "get package yd"
          command: |
            sudo wget https://github.com/mikefarah/yq/releases/download/v4.19.1/yq_linux_amd64 -O /usr/bin/yq &&\
            sudo chmod +x /usr/bin/yq
  destroy-environment:
    description: Destroy created resource on failure.
    steps:
      - run:
          name: Destroy created nodegroup
          when: on_fail
          command: |
            eksctl delete nodegroup node-${CIRCLE_WORKFLOW_ID:0:7}

jobs:
  build-frontend:
    docker:
      - image: cimg/node:14.17.3
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build

  build-backend:
    docker:
      - image: cimg/node:14.17.3
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
             cd backend
             npm install
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
  
  ## lint backend
  
  test-frontend:
    docker:
      - image: cimg/node:14.17.3
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Frontend Test
          command: |
            cd frontend
            npm install
            npm run test

  scan-backend:
    docker:
      - image: cimg/node:14.17.3
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Analyse code
          command: |
            cd backend
            npm install
            npm audit fix --audit-level=critical --force
            npm audit --audit-level=critical

  ## create node using eksctl set lable
  create-nodegroup:
    docker:
      - image: 'cimg/python:3.10'
    steps:
      - checkout
      - install-yd
      - run:
          name: "install eksctl"
          command: |
            curl --silent --location \
            "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | \
            tar xz -C /tmp 
            sudo mv /tmp/eksctl /usr/local/bin
      - run:
          name: "update config with variables"
          command: |
            NAME=node-${CIRCLE_WORKFLOW_ID:0:7}
            WFLOW=${CIRCLE_WORKFLOW_ID:0:7}
            WFLOW=$WFLOW yq eval -i '.managedNodeGroups[0].labels.workflow = strenv(WFLOW)' \
            ./deployment/cf-templates/eks-node.yml
            NAME=$NAME yq eval -i '.managedNodeGroups[0].name = strenv(NAME)' \
            ./deployment/cf-templates/eks-node.yml
            cat ./deployment/cf-templates/eks-node.yml
      - run:
          name: "create nodegroup with eskctl"
          command: |
            eksctl create nodegroup -f deployment/cf-templates/eks-node.yml
      - destroy-environment
        
      
  ## create a deployment on new node
  deploy-to-cluster:
    docker:
      - image: 'cimg/python:3.10'
    steps:
      - checkout
      - kubernetes/install
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: geohospital
      - install-yd
      - run:
          name: create deployment & service to select new node
          command: |
            WFLOW=${CIRCLE_WORKFLOW_ID:0:7}
            IMAGE=681986958382.dkr.ecr.us-east-1.amazonaws.com/geohospital:${WFLOW}
            DP_NAME=deployment-${WFLOW}
            APP=geohospital-${WFLOW}
            SVR_NAME=service-${WFLOW}
            WFLOW=$WFLOW yq eval -i '.spec.template.spec.nodeSelector.workflow = strenv(WFLOW)' \
            ./deployment/deployment.yml
            IMAGE=$IMAGE yq eval -i '.spec.template.spec.containers[0].image = strenv(IMAGE)' \
            ./deployment/deployment.yml
            NAME=$DP_NAME yq eval -i '.metadata.name = strenv(NAME)' \
            ./deployment/deployment.yml
            APP=$APP yq eval -i '.metadata.labels.app = strenv(APP)' \
            ./deployment/deployment.yml
            APP=$APP yq eval -i '.spec.selector.matchLabels.app = strenv(APP)' \
            ./deployment/deployment.yml
            APP=$APP yq eval -i '.spec.template.metadata.labels.app = strenv(APP)' \
            ./deployment/deployment.yml
            SVR=$SVR_NAME yq eval -i '.metadata.name = strenv(SVR)' \
            ./deployment/loadbalancer.yml
            APP=$APP yq eval -i '.spec.selector.app = strenv(APP)' \
            ./deployment/loadbalancer.yml
            cat ./deployment/deployment.yml
            cat ./deployment/loadbalancer.yml  
      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: ./deployment/deployment.yml
          resource-name: deployment/deployment-${CIRCLE_WORKFLOW_ID:0:7}
      - kubernetes/create-or-update-resource:
          resource-file-path: ./deployment/loadbalancer.yml
          resource-name: service/service-${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: show resource
          command: |
            kubectl get deployments
            kubectl get services
      - destroy-environment
  
  smoke-test: 
    docker:
      - image: 'cimg/python:3.10'
    steps:
      - checkout
      - kubernetes/install
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: geohospital
      - run:
          name: test deployment url
          command: |
            WFLOW=${CIRCLE_WORKFLOW_ID:0:7}
            sleep 25
            kubectl get service/service-${WFLOW} | awk {'print $4'} | grep ".com" \
            >> url.txt
            cat url.txt
            # URL=http://$(cat url.txt)
            # RES=$(curl $URL \
            # -X POST \
            # -H 'content-type: application/json' \
            # --data '{
            #   "query": "{ continents { code name } }"
            # }')
            # if echo $RES | grep "GraphQLError"
            # then
            #   return 0
            # else
            #   return 1
            # fi
      - persist_to_workspace:
          root: ~/
          paths:
            - .
  
  deploy-frontend-to-s3:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - run:
          name: Install project dep
          command: |
            apk update && \
            apk add nodejs npm
      - run:
          name: Install aws cli
          command: python -m pip install awscli
      - run:
          name: create s3 bucket
          command: |
            aws cloudformation deploy \
              --template-file deployment/cf-templates/bucket.yml \
              --tags project=geohospital-frontend \
              --stack-name "geohospital-frontend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"
      - run:
          name: Deploy frontend objects
          command: |
            REACT_APP_URL=http://$(cat url.txt)
            cd frontend
            npm install
            npm run build
            tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7}".tar.gz build
            aws s3 cp dist s3://geohospital-${CIRCLE_WORKFLOW_ID:0:7} --recursive
      - run:
          name: Destroy created resource
          when: on_fail
          command: |
            aws s3 rb s3://geohospital-${CIRCLE_WORKFLOW_ID:0:7} --force
            aws cloudformation delete-stack \
            --stack-name "geohospital-frontend-${CIRCLE_WORKFLOW_ID:0:7}"

  cloudfront-update:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install tar utility dependencies
          command: |
            yum install -y tar gzip
      - run:
          name: Save old workflow
          command: |
            export OldWorkflowID=$(aws cloudformation \
            list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
            --no-paginate --output text)
            echo $OldWorkflowID >> OldWorkflowID.txt
      - run:
          name: Update cloudfront distribution
          command: |
            aws cloudformation deploy \
            --template-file deployment/cf-templates/cloudfront.yml \
            --stack-name InitialStack \
            --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" \
            --tags project=geohospital
            echo Current WorkflowId: "{CIRCLE_WORKFLOW_ID:0:7}"
      - persist_to_workspace:
          root: ~/
          paths:
            - .

  clean-up:
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Install tar utility dependencies
            command: |
              yum install -y tar gzip
        - attach_workspace:
            at: ~/
        - run:
            name: Delete stacks and files
            command: |
              cat OldWorkflowID.txt

workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - scan-backend:
          requires: [build-backend]
      - create-nodegroup:
          requires: 
            - scan-backend
      - aws-ecr/build-and-push-image:
          account-url: AWS_ECR_ACCOUNT_URL
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          create-repo: true
          no-output-timeout: 20m
          region: AWS_DEFAULT_REGION
          repo: geohospital
          skip-when-tags-exist: false
          tag:  ${CIRCLE_WORKFLOW_ID:0:7}
          requires:
            - build-backend
      - deploy-to-cluster:
          requires:
            - aws-ecr/build-and-push-image
            - create-nodegroup
      - smoke-test:
          requires:
            - deploy-to-cluster
      - deploy-frontend-to-s3:
          requires: 
            - smoke-test
      - cloudfront-update:
          requires:
            - deploy-frontend-to-s3
      - clean-up:
          requires:
            - cloudfront-update

